{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1wtnL0Ir9xs8-BmzcLENbDFs_ZF6Nvdfc",
      "authorship_tag": "ABX9TyO/OkZaGyhRlgj3vxaVeZAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoCasPer/T_Aprendizaje_Maquina/blob/main/Parcial1_TAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parcial 1 Teoría de aprendizaje de máquina\n",
        "Preguntas 2 y 3:\n",
        "\n",
        "Nicolás Castaño Pérez /1054398549\n",
        "\n",
        "Mayo 2025\n"
      ],
      "metadata": {
        "id": "SFUbGc-hlZFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install streamlit -q #instalación de librerías\n",
        "!pip install pyngrok\n",
        "!pip install optuna\n",
        "!pip install streamlit pandas matplotlib seaborn scikit-learn pyngrok kagglehub\n",
        "!pip install pyngrok streamlit --quiet"
      ],
      "metadata": {
        "id": "JGcLkJ8pvLok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile TAMExam1.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import altair as alt\n",
        "import pydeck as pdk\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
        "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "from scipy.stats import loguniform, uniform, randint\n",
        "from joblib import dump\n",
        "from urllib.error import URLError\n",
        "\n",
        "# Configuración de la página de Streamlit\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Análisis y Modelización de Ames Housing\")\n",
        "\n",
        "# Título\n",
        "st.title('Análisis y Modelización de Precios de Viviendas - Ames Housing')\n",
        "\n",
        "# Documentación Formal: Introducción\n",
        "st.header('Documentación Formal: Análisis Exploratorio y Modelización')\n",
        "st.markdown(\"\"\"\n",
        "### Introducción\n",
        "Este dashboard presenta el análisis exploratorio de datos (EDA), el preprocesamiento y la modelización del dataset Ames Housing para predecir el precio de venta ('SalePrice'). El dataset incluye 2930 observaciones y 81 características. Este trabajo cumple con los requisitos del punto 3 del examen de Teoría de Aprendizaje de Máquina.\n",
        "\n",
        "### Descripción de los Datos\n",
        "El dataset Ames Housing contiene variables numéricas (como 'GrLivArea', 'TotalBsmtSF') y categóricas (como 'Neighborhood', 'MSZoning'). La variable objetivo es 'SalePrice'.\n",
        "\n",
        "### Metodología\n",
        "- **Preprocesamiento:** Manejo de valores faltantes (mediana para numéricas, moda o 'missing' para categóricas), codificación de variables categóricas (One-Hot para nominales, Ordinal para ordinales), ingeniería de características (creación de 'Age' y 'TotalSF'), y escalado de variables numéricas.\n",
        "- **EDA:** Visualizaciones para entender la distribución de variables y su relación con 'SalePrice'.\n",
        "- **Modelización:** Entrenamiento de múltiples modelos de regresión con optimización de hiperparámetros (GridSearchCV, RandomizedSearchCV, BayesSearchCV), evaluación con métricas MAE, MSE, R2 y MAPE.\n",
        "- **Dashboard:** Visualización interactiva de los datos y comparación de los tres mejores modelos.\n",
        "\"\"\")\n",
        "\n",
        "# Cargar los datos\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    try:\n",
        "        df = pd.read_csv('/content/drive/Shareddrives/UNAL_Colab/Teoría de Aprendizaje de Máquina/AmesHousing.csv')\n",
        "        df.columns = df.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"Error: Asegúrese de que el archivo 'AmesHousing.csv' esté disponible.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "df = load_data()\n",
        "if df.empty:\n",
        "    st.stop()\n",
        "\n",
        "st.subheader(\"Datos Originales (primeras 5 filas)\")\n",
        "st.dataframe(df.head())\n",
        "\n",
        "# Documentación Formal: Preprocesamiento\n",
        "st.header('Preprocesamiento de Datos')\n",
        "st.markdown(\"\"\"\n",
        "### Metodología de Preprocesamiento\n",
        "El preprocesamiento asegura que los datos estén limpios y listos para el modelado, abordando los siguientes pasos:\n",
        "\n",
        "1. **Manejo de Valores Faltantes**\n",
        "   - **Numéricas:** Se imputaron con la mediana para columnas como 'LotFrontage' y 'GarageYrBlt', ya que es robusta frente a outliers.\n",
        "   - **Categóricas:** Se imputaron con 'missing' para columnas como 'Alley', 'Fence', 'MiscFeature', 'PoolQC' y 'FireplaceQu', reconociendo que la ausencia de datos puede ser informativa (por ejemplo, 'missing' en 'Alley' indica que no hay callejón). Otras categóricas, como 'MasVnrType' y 'Electrical', se imputaron con la moda para preservar la distribución.\n",
        "   - **Justificación:** La mediana minimiza el impacto de valores extremos en numéricas, mientras que 'missing' y la moda son adecuadas para categóricas según el contexto.\n",
        "\n",
        "2. **Codificación de Variables Categóricas**\n",
        "   - **Nominales:** Columnas como 'MSZoning', 'Neighborhood', 'MasVnrType' se codificaron con One-Hot Encoding, generando variables binarias para cada categoría, eliminando la primera categoría para evitar multicolinealidad.\n",
        "   - **Ordinales:** Columnas como 'ExterQual', 'BsmtQual', 'HeatingQC' se codificaron con Ordinal Encoding, asignando valores numéricos según un orden definido (por ejemplo, 'Po' < 'Fa' < 'TA' < 'Gd' < 'Ex').\n",
        "   - **Justificación:** One-Hot Encoding es ideal para variables sin orden inherente, mientras que Ordinal Encoding respeta la jerarquía en variables de calidad o condición.\n",
        "\n",
        "3. **Ingeniería de Características**\n",
        "   - **TotalSF:** Suma de 'TotalBsmtSF', '1stFlrSF' y '2ndFlrSF', representando el área total habitable.\n",
        "   - **Age:** Diferencia entre 'YrSold' y 'YearBuilt', indicando la antigüedad de la propiedad.\n",
        "   - **Justificación:** Estas características combinan información relevante, reduciendo la dimensionalidad y capturando factores clave que afectan el precio de venta.\n",
        "\n",
        "4. **Escalado de Variables Numéricas**\n",
        "   - Se aplicó `StandardScaler` a todas las variables numéricas, transformándolas a una distribución con media 0 y desviación estándar 1.\n",
        "   - **Justificación:** El escalado es esencial para modelos sensibles a la escala, como KernelRidge o SVR, y mejora la comparabilidad entre características.\n",
        "\n",
        "5. **Análisis de Correlaciones**\n",
        "   - Se identificaron pares de características con correlaciones altas (>0.8), como 'TotalBsmtSF' y '1stFlrSF', para evaluar redundancias.\n",
        "   - **Justificación:** Eliminar características redundantes reduce el riesgo de multicolinealidad y mejora la eficiencia del modelado.\n",
        "\n",
        "**Guardado de Datos Preprocesados**\n",
        "Los datos preprocesados se guardan en 'preprocessed_data.csv' para su uso en el entrenamiento de modelos, asegurando consistencia y evitando reprocesamiento redundante.\n",
        "\"\"\")\n",
        "\n",
        "# Preprocesamiento\n",
        "@st.cache_data\n",
        "def preprocess_data(df):\n",
        "    df_processed = df.copy()\n",
        "    threshold = len(df_processed) * 0.5\n",
        "    cols_to_drop_nulls = df_processed.columns[df_processed.isnull().sum() > threshold].tolist()\n",
        "    df_processed = df_processed.drop(columns=cols_to_drop_nulls)\n",
        "    st.sidebar.write(f\"Columnas eliminadas por exceso de nulos (>50%): {cols_to_drop_nulls}\")\n",
        "\n",
        "    numerical_cols = df_processed.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_cols = df_processed.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "    numeric_cols_median = ['LotFrontage', 'GarageYrBlt']\n",
        "    categorical_cols_mode = ['MasVnrType', 'Electrical']\n",
        "    categorical_cols_missing = ['Alley', 'Fence', 'MiscFeature', 'PoolQC', 'FireplaceQu']\n",
        "\n",
        "    for col in numeric_cols_median:\n",
        "        if col in df_processed.columns and df_processed[col].isnull().any():\n",
        "            imputer_median = SimpleImputer(strategy='median')\n",
        "            df_processed[col] = imputer_median.fit_transform(df_processed[[col]]).ravel()\n",
        "\n",
        "    for col in categorical_cols_mode:\n",
        "        if col in df_processed.columns and df_processed[col].isnull().any():\n",
        "            imputer_mode = SimpleImputer(strategy='most_frequent')\n",
        "            df_processed[col] = imputer_mode.fit_transform(df_processed[[col]]).ravel()\n",
        "\n",
        "    for col in categorical_cols_missing:\n",
        "        if col in df_processed.columns and df_processed[col].isnull().any():\n",
        "            imputer_missing = SimpleImputer(strategy='constant', fill_value='missing')\n",
        "            df_processed[col] = imputer_missing.fit_transform(df_processed[[col]]).ravel()\n",
        "\n",
        "    if 'YearBuilt' in df_processed.columns:\n",
        "        df_processed['Age'] = 2023 - df_processed['YearBuilt']\n",
        "        df_processed = df_processed.drop(columns=['YearBuilt'])\n",
        "    if 'YearRemodAdd' in df_processed.columns:\n",
        "        df_processed['YearsSinceRemodel'] = 2023 - df_processed['YearRemodAdd']\n",
        "        df_processed = df_processed.drop(columns=['YearRemodAdd'])\n",
        "    if all(col in df_processed.columns for col in ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF']):\n",
        "        df_processed['TotalSF'] = df_processed['TotalBsmtSF'] + df_processed['1stFlrSF'] + df_processed['2ndFlrSF']\n",
        "\n",
        "    nominal_cols = ['MSZoning', 'Neighborhood', 'MasVnrType', 'Exterior1st', 'Exterior2nd', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'SaleType', 'SaleCondition']\n",
        "    nominal_cols = [col for col in nominal_cols if col in df_processed.columns]\n",
        "    ordinal_mapping = {\n",
        "        'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex', 'missing'],\n",
        "        'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex', 'missing'],\n",
        "        'BsmtQual': ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'BsmtCond': ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'FireplaceQu': ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'GarageQual': ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'GarageCond': ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
        "        'PoolQC': ['missing', 'Fa', 'Gd', 'Ex']\n",
        "    }\n",
        "    ordinal_cols = [col for col in ordinal_mapping.keys() if col in df_processed.columns]\n",
        "\n",
        "    if nominal_cols:\n",
        "        df_processed = pd.get_dummies(df_processed, columns=nominal_cols, drop_first=True)\n",
        "    if ordinal_cols:\n",
        "        ordinal_encoder = OrdinalEncoder(categories=[ordinal_mapping[col] for col in ordinal_cols])\n",
        "        df_processed[ordinal_cols] = ordinal_encoder.fit_transform(df_processed[ordinal_cols])\n",
        "\n",
        "    numeric_cols_to_scale = df_processed.select_dtypes(include=np.number).columns.tolist()\n",
        "    if 'SalePrice' in numeric_cols_to_scale:\n",
        "        numeric_cols_to_scale.remove('SalePrice')\n",
        "    if 'Id' in numeric_cols_to_scale:\n",
        "        numeric_cols_to_scale.remove('Id')\n",
        "    if numeric_cols_to_scale:\n",
        "        scaler = StandardScaler()\n",
        "        df_processed[numeric_cols_to_scale] = scaler.fit_transform(df_processed[numeric_cols_to_scale])\n",
        "\n",
        "    numeric_df = df_processed.select_dtypes(include=np.number)\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    correlation_threshold = 0.8\n",
        "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "    to_drop_high_corr = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n",
        "    st.sidebar.write(f\"Columnas con alta correlación (> {correlation_threshold}): {to_drop_high_corr}\")\n",
        "\n",
        "    # Guardar datos preprocesados\n",
        "    df_processed.to_csv('preprocessed_data.csv', index=False)\n",
        "    return df_processed\n",
        "\n",
        "df_processed = preprocess_data(df.copy())\n",
        "st.subheader(\"Datos Preprocesados (primeras 5 filas)\")\n",
        "st.dataframe(df_processed.head())\n",
        "\n",
        "# Documentación Formal: Visualizaciones\n",
        "st.header('Análisis Exploratorio de Datos')\n",
        "st.markdown(\"\"\"\n",
        "### Visualizaciones Clave\n",
        "El análisis exploratorio utiliza visualizaciones para identificar patrones, distribuciones y relaciones en el dataset:\n",
        "\n",
        "1. **Distribución de SalePrice**\n",
        "   - **Histograma:** Muestra la distribución de los precios de venta, con un sesgo positivo que indica una mayoría de propiedades de menor valor y algunos outliers de alto valor.\n",
        "   - **Boxplot:** Identifica outliers en los precios altos, sugiriendo la necesidad de transformaciones o manejo de valores extremos.\n",
        "\n",
        "2. **Distribución de Variables Numéricas**\n",
        "   - Histogramas y boxplots para variables como 'GrLivArea', 'TotalBsmtSF', 'Age', 'TotalSF' muestran sus distribuciones y posibles outliers, proporcionando información sobre su impacto en el precio.\n",
        "\n",
        "3. **Relación con SalePrice**\n",
        "   - Gráficos de dispersión entre 'SalePrice' y las variables más correlacionadas (como 'OverallQual', 'GrLivArea') revelan relaciones lineales y no lineales, destacando características predictivas clave.\n",
        "\n",
        "4. **Distribución de Variables Categóricas**\n",
        "   - Gráficos de barras para variables como 'Neighborhood' y 'MSZoning' muestran la frecuencia de categorías, ayudando a entender su distribución y posible influencia en 'SalePrice'.\n",
        "\n",
        "5. **Matriz de Correlación**\n",
        "   - Un mapa de calor identifica correlaciones entre variables numéricas, destacando relaciones fuertes y posibles redundancias.\n",
        "\"\"\")\n",
        "\n",
        "# Visualizaciones\n",
        "st.sidebar.subheader(\"Opciones de Visualización\")\n",
        "viz_option = st.sidebar.selectbox(\"Selecciona una visualización:\",\n",
        "                                  [\"Distribución de SalePrice\",\n",
        "                                   \"Mapa de Calor de Correlación\",\n",
        "                                   \"Relación con SalePrice (Scatter plots)\",\n",
        "                                   \"Distribución de Variables Categóricas\",\n",
        "                                   \"Distribución de Variables Numéricas\"])\n",
        "\n",
        "if viz_option == \"Distribución de SalePrice\":\n",
        "    st.subheader(\"Distribución de SalePrice\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    sns.histplot(df['SalePrice'], kde=True, ax=axes[0])\n",
        "    axes[0].set_title('Distribución de SalePrice')\n",
        "    axes[0].set_xlabel('SalePrice')\n",
        "    axes[0].set_ylabel('Frecuencia')\n",
        "    sns.boxplot(y=df['SalePrice'], ax=axes[1])\n",
        "    axes[1].set_title('Boxplot de SalePrice')\n",
        "    axes[1].set_ylabel('SalePrice')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    st.markdown(\"\"\"\n",
        "    **Análisis:** La distribución de 'SalePrice' muestra un sesgo positivo (skewness > 0.5), con outliers en valores altos. Esto sugiere considerar una transformación logarítmica para normalizar los datos en el modelado.\n",
        "    \"\"\")\n",
        "\n",
        "elif viz_option == \"Mapa de Calor de Correlación\":\n",
        "    st.subheader(\"Mapa de Calor de Correlación\")\n",
        "    numeric_df = df_processed.select_dtypes(include=np.number)\n",
        "    if 'SalePrice' in numeric_df.columns:\n",
        "        correlation_with_saleprice = numeric_df.corr()['SalePrice'].sort_values(ascending=False)\n",
        "        st.write(\"Correlación de variables numéricas con SalePrice:\")\n",
        "        st.dataframe(correlation_with_saleprice)\n",
        "        fig, ax = plt.subplots(figsize=(8, 10))\n",
        "        sns.heatmap(correlation_with_saleprice.to_frame(), cmap='coolwarm', annot=True, fmt=\".2f\", cbar=False, ax=ax)\n",
        "        ax.set_title('Correlación con SalePrice')\n",
        "        ax.tick_params(axis='y', rotation=0)\n",
        "        st.pyplot(fig)\n",
        "        st.markdown(\"\"\"\n",
        "        **Análisis:** Variables como 'OverallQual' y 'GrLivArea' tienen correlaciones altas con 'SalePrice', indicando su importancia predictiva. Las correlaciones negativas son menos comunes, pero pueden reflejar factores como la antigüedad ('Age').\n",
        "        \"\"\")\n",
        "\n",
        "elif viz_option == \"Relación con SalePrice (Scatter plots)\":\n",
        "    st.subheader(\"Relación entre SalePrice y Variables Numéricas Clave\")\n",
        "    numeric_df = df_processed.select_dtypes(include=np.number)\n",
        "    if 'SalePrice' in numeric_df.columns:\n",
        "        correlation_with_saleprice = numeric_df.corr()['SalePrice'].sort_values(ascending=False)\n",
        "        top_n = st.slider(\"Número de variables más correlacionadas a mostrar:\", 3, 10, 5)\n",
        "        top_correlated_cols = correlation_with_saleprice.head(top_n + 1).index.tolist()\n",
        "        if 'SalePrice' in top_correlated_cols:\n",
        "            top_correlated_cols.remove('SalePrice')\n",
        "        st.write(f\"Mostrando la relación de SalePrice con las {len(top_correlated_cols)} variables más correlacionadas:\")\n",
        "        num_cols_plot = 3\n",
        "        num_rows_plot = int(np.ceil(len(top_correlated_cols) / num_cols_plot))\n",
        "        fig, axes = plt.subplots(num_rows_plot, num_cols_plot, figsize=(15, 5 * num_rows_plot))\n",
        "        axes = axes.flatten() if num_rows_plot > 1 else [axes]\n",
        "        for i, col in enumerate(top_correlated_cols):\n",
        "            if col in numeric_df.columns:\n",
        "                sns.scatterplot(x=numeric_df[col], y=numeric_df['SalePrice'], ax=axes[i])\n",
        "                axes[i].set_title(f'SalePrice vs {col}')\n",
        "                axes[i].set_xlabel(col)\n",
        "                axes[i].set_ylabel('SalePrice')\n",
        "            else:\n",
        "                axes[i].set_visible(False)\n",
        "        for j in range(i + 1, len(axes)):\n",
        "            axes[j].set_visible(False)\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig)\n",
        "        st.markdown(\"\"\"\n",
        "        **Análisis:** Los gráficos de dispersión muestran relaciones lineales y no lineales entre 'SalePrice' y variables clave, como 'GrLivArea' (positiva) y 'Age' (potencialmente negativa), destacando su relevancia para la predicción.\n",
        "        \"\"\")\n",
        "\n",
        "elif viz_option == \"Distribución de Variables Categóricas\":\n",
        "    st.subheader(\"Distribución de Variables Categóricas\")\n",
        "    df_original = load_data()\n",
        "    df_original.columns = df_original.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
        "    categorical_cols = df_original.select_dtypes(include='object').columns.tolist()\n",
        "    for col in categorical_cols:\n",
        "        if df_original[col].isnull().any():\n",
        "            df_original[col].fillna('Missing', inplace=True)\n",
        "    if categorical_cols:\n",
        "        selected_cols = st.multiselect(\"Selecciona variables categóricas para visualizar:\", categorical_cols, default=categorical_cols[:5])\n",
        "        if selected_cols:\n",
        "            num_cols_plot = 2\n",
        "            num_rows_plot = int(np.ceil(len(selected_cols) / num_cols_plot))\n",
        "            fig, axes = plt.subplots(num_rows_plot, num_cols_plot, figsize=(15, 5 * num_rows_plot))\n",
        "            axes = axes.flatten() if num_rows_plot > 1 else [axes]\n",
        "            for i, col in enumerate(selected_cols):\n",
        "                if col in df_original.columns and df_original[col].dtype == 'object':\n",
        "                    sns.countplot(y=col, data=df_original, order=df_original[col].value_counts().index, ax=axes[i])\n",
        "                    axes[i].set_title(f'Distribución de {col}')\n",
        "                    axes[i].set_xlabel('Frecuencia')\n",
        "                    axes[i].set_ylabel(col)\n",
        "                else:\n",
        "                    axes[i].set_visible(False)\n",
        "            for j in range(i + 1, len(axes)):\n",
        "                axes[j].set_visible(False)\n",
        "            plt.tight_layout()\n",
        "            st.pyplot(fig)\n",
        "            st.markdown(\"\"\"\n",
        "            **Análisis:** Los gráficos de barras muestran la distribución de categorías, como 'Neighborhood', revelando la composición del dataset y posibles influencias en 'SalePrice'.\n",
        "            \"\"\")\n",
        "\n",
        "elif viz_option == \"Distribución de Variables Numéricas\":\n",
        "    st.subheader(\"Distribución de Variables Numéricas\")\n",
        "    numeric_cols = df_processed.select_dtypes(include=np.number).columns.tolist()\n",
        "    if 'SalePrice' in numeric_cols:\n",
        "        numeric_cols.remove('SalePrice')\n",
        "    if numeric_cols:\n",
        "        selected_cols = st.multiselect(\"Selecciona variables numéricas para visualizar:\", numeric_cols, default=numeric_cols[:5])\n",
        "        if selected_cols:\n",
        "            num_cols_plot = 3\n",
        "            num_rows_plot = int(np.ceil(len(selected_cols) / num_cols_plot)) * 2\n",
        "            fig, axes = plt.subplots(num_rows_plot, num_cols_plot, figsize=(15, 5 * num_rows_plot/2))\n",
        "            axes = axes.flatten() if num_rows_plot > 1 else [axes]\n",
        "            plot_index = 0\n",
        "            for i, col in enumerate(selected_cols):\n",
        "                if col in df_processed.columns and df_processed[col].dtype in [np.number]:\n",
        "                    sns.histplot(df_processed[col], kde=True, ax=axes[plot_index])\n",
        "                    axes[plot_index].set_title(f'Distribución de {col}')\n",
        "                    axes[plot_index].set_xlabel(col)\n",
        "                    axes[plot_index].set_ylabel('Frecuencia')\n",
        "                    plot_index += 1\n",
        "                    sns.boxplot(y=df_processed[col], ax=axes[plot_index])\n",
        "                    axes[plot_index].set_title(f'Boxplot de {col}')\n",
        "                    axes[plot_index].set_ylabel(col)\n",
        "                    plot_index += 1\n",
        "                else:\n",
        "                    axes[plot_index].set_visible(False)\n",
        "                    axes[plot_index+1].set_visible(False)\n",
        "                    plot_index += 2\n",
        "            for j in range(plot_index, len(axes)):\n",
        "                axes[j].set_visible(False)\n",
        "            plt.tight_layout()\n",
        "            st.pyplot(fig)\n",
        "            st.markdown(\"\"\"\n",
        "            **Análisis:** Los histogramas y boxplots muestran la distribución y presencia de outliers en variables numéricas, como 'GrLivArea' y 'TotalSF', proporcionando información sobre su impacto en el modelado.\n",
        "            \"\"\")\n",
        "\n",
        "# Documentación Formal: Modelización\n",
        "# Documentación Formal: Modelización\n",
        "st.header('Modelización de Datos')\n",
        "st.markdown(\"\"\"\n",
        "### Metodología de Modelización\n",
        "Se entrenaron y evaluaron múltiples modelos de regresión para predecir 'SalePrice', utilizando validación cruzada de 5 pliegues y optimización de hiperparámetros con GridSearchCV, RandomizedSearchCV y BayesSearchCV. Los modelos son:\n",
        "\n",
        "- **LinearRegression**: Modelo base para relaciones lineales simples, sin optimización de hiperparámetros debido a su simplicidad.\n",
        "- **Lasso**: Regularización L1 para selección de características, útil para datasets con multicolinealidad.\n",
        "- **ElasticNet**: Combina regularización L1 y L2, balanceando selección y estabilidad.\n",
        "- **KernelRidge**: Captura relaciones no lineales mediante un kernel RBF, adecuado para patrones complejos.\n",
        "- **SGDRegressor**: Optimización basada en gradiente descendente, eficiente para datasets grandes.\n",
        "- **BayesianRidge**: Modelo bayesiano robusto a multicolinealidad, con parámetros predeterminados.\n",
        "- **RandomForestRegressor**: Ensamblado de árboles, robusto a valores faltantes y relaciones no lineales.\n",
        "- **SVR**: Máquinas de soporte vectorial con kernel RBF, efectivas para relaciones no lineales.\n",
        "\n",
        "### Optimización de Hiperparámetros\n",
        "Se utilizaron tres métodos de optimización:\n",
        "- **GridSearchCV**: Explora exhaustivamente un conjunto finito de hiperparámetros, garantizando la mejor combinación dentro del rango definido.\n",
        "- **RandomizedSearchCV**: Muestrea aleatoriamente combinaciones de hiperparámetros, eficiente para espacios grandes.\n",
        "- **BayesSearchCV**: Usa optimización bayesiana para explorar el espacio de hiperparámetros de manera eficiente, priorizando combinaciones prometedoras.\n",
        "\n",
        "### Rangos de Hiperparámetros y Justificación\n",
        "- **Lasso**:\n",
        "  - **GridSearchCV**: `alpha = [0.001, 0.01, 0.1, 1, 10]`. Rango logarítmico para cubrir diferentes niveles de regularización, desde baja (0.001) hasta alta (10), permitiendo selección de características efectiva.\n",
        "  - **RandomizedSearchCV/BayesSearchCV**: `alpha = loguniform(0.001, 10)`. La distribución loguniforme explora un rango continuo, capturando valores pequeños y grandes para adaptarse a la escala de los datos.\n",
        "- **ElasticNet**:\n",
        "  - **GridSearchCV**: `alpha = [0.001, 0.01, 0.1, 1]`, `l1_ratio = [0.1, 0.3, 0.5]`. Rangos discretos para balancear regularización L1 y L2, enfocándose en valores bajos para evitar sobre-regularización.\n",
        "  - **RandomizedSearchCV/BayesSearchCV**: `alpha = loguniform(0.001, 1)`, `l1_ratio = uniform(0, 1)`. La distribución loguniforme para `alpha` cubre un espectro amplio, mientras que `l1_ratio` explora todo el rango de balance entre L1 y L2.\n",
        "- **KernelRidge**:\n",
        "  - **GridSearchCV**: `alpha = [0.001, 0.01, 0.1]`, `gamma = [0.001, 0.01]`. Rangos discretos para regularización y escala del kernel RBF, enfocados en valores pequeños para capturar no linealidades.\n",
        "  - **RandomizedSearchCV/BayesSearchCV**: `alpha = loguniform(0.001, 1)`, `gamma = loguniform(0.001, 1)`. Distribuciones loguniformes para explorar un rango continuo, adecuado para la sensibilidad del kernel RBF.\n",
        "- **SGDRegressor**:\n",
        "  - **GridSearchCV**: `alpha = [0.0001, 0.001]`. Rangos pequeños para regularización, ya que valores grandes pueden causar inestabilidad en el gradiente descendente.\n",
        "  - **RandomizedSearchCV/BayesSearchCV**: `alpha = loguniform(0.0001, 0.01)`. Rango logarítmico para explorar regularización fina, manteniendo estabilidad.\n",
        "- **RandomForestRegressor**:\n",
        "  - **GridSearchCV**: `n_estimators = [50, 100]`, `max_depth = [None, 10]`, `min_samples_split = [2, 5]`. Rangos reducidos para acelerar la optimización, cubriendo un número moderado de árboles y profundidades.\n",
        "  - **RandomizedSearchCV**: `n_estimators = randint(50, 150)`, `max_depth = [None] + list(range(5, 15))`, `min_samples_split = randint(2, 10)`. Rangos discretos para explorar complejidad del modelo.\n",
        "  - **BayesSearchCV**: `n_estimators = Integer(50, 150)`, `max_depth = Integer(5, 15)`, `min_samples_split = Integer(2, 10)`. Rangos continuos para una búsqueda más precisa.\n",
        "- **SVR**:\n",
        "  - **GridSearchCV**: `C = [1, 10, 100]`, `epsilon = [0.01, 0.1, 0.5]`, `gamma = ['scale', 'auto', 0.001]`. Rangos discretos para regularización, margen y escala del kernel.\n",
        "  - **RandomizedSearchCV/BayesSearchCV**: `C = loguniform(0.1, 1000)`, `epsilon = uniform(0.001, 1)`, `gamma = loguniform(0.0001, 1)`. Distribuciones continuas para explorar un espacio amplio.\n",
        "- **LinearRegression y BayesianRidge**: Sin optimización de hiperparámetros, ya que sus parámetros predeterminados son robustos para el dataset.\n",
        "\n",
        "### Número de Iteraciones\n",
        "- **RandomizedSearchCV y BayesSearchCV**: Se usaron 10 iteraciones para RandomForestRegressor y 50-100 para otros modelos, para balancear precisión y tiempo de cómputo. Menos iteraciones (10) se usaron en RandomForestRegressor debido a su alto costo computacional, mientras que 50-100 iteraciones en modelos más rápidos (como Lasso, ElasticNet) permiten una exploración más exhaustiva.\n",
        "- **Justificación**: El número de iteraciones refleja un compromiso entre explorar el espacio de hiperparámetros y mantener la eficiencia computacional, considerando que el dataset Ames Housing (~1460 filas tras división) no requiere búsquedas extensas para modelos lineales, pero sí para modelos no lineales.\n",
        "\n",
        "### Evaluación\n",
        "Se utilizó validación cruzada de 5 pliegues para garantizar estimaciones robustas de las métricas MAE, MSE, R2 y MAPE. Los resultados se guardan en un archivo pickle ('/content/model_results.pkl') para su uso en el dashboard de Streamlit. Los mejores estimadores se guardan con joblib para pruebas posteriores.\n",
        "\"\"\")\n",
        "\n",
        "# Entrenamiento de Modelos\n",
        "st.subheader(\"Entrenamiento de Modelos\")\n",
        "\n",
        "# Verificar si los resultados ya existen para evitar reentrenamiento\n",
        "if not os.path.exists('/content/model_results.pkl'):\n",
        "    try:\n",
        "        # Cargar datos preprocesados\n",
        "        st.write(\"Cargando datos preprocesados desde preprocessed_data.csv...\")\n",
        "        df = pd.read_csv('preprocessed_data.csv')\n",
        "\n",
        "        # Separar características y variable objetivo\n",
        "        st.write(\"Separando características y variable objetivo...\")\n",
        "        if 'SalePrice' in df.columns:\n",
        "            y = df['SalePrice']\n",
        "            X = df.drop('SalePrice', axis=1)\n",
        "        else:\n",
        "            st.error(\"La columna 'SalePrice' no se encontró.\")\n",
        "            st.stop()\n",
        "\n",
        "        # Asegurarse de que X sea numérico\n",
        "        X = X.select_dtypes(include=np.number)\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]\n",
        "\n",
        "        # División en conjuntos de entrenamiento y prueba\n",
        "        st.write(\"Dividiendo datos en entrenamiento y prueba...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Definir métricas\n",
        "        def mean_absolute_percentage_error(y_true, y_pred):\n",
        "            y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "            epsilon = 1e-8\n",
        "            return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "        scoring = {\n",
        "            'mae': make_scorer(mean_absolute_error, greater_is_better=False),\n",
        "            'mse': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "            'r2': make_scorer(r2_score, greater_is_better=True),\n",
        "            'mape': make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
        "        }\n",
        "        scoring_optimizer = {'mae': make_scorer(mean_absolute_error, greater_is_better=False)}\n",
        "\n",
        "        # Configurar KFold\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        # Definir modelos y espacios de búsqueda\n",
        "        models = {\n",
        "            'LinearRegression': LinearRegression(),\n",
        "            'Lasso': Lasso(random_state=42, max_iter=10000),\n",
        "            'ElasticNet': ElasticNet(random_state=42, max_iter=10000),\n",
        "            'KernelRidge': KernelRidge(kernel='rbf'),\n",
        "            'SGDRegressor': SGDRegressor(learning_rate='invscaling', early_stopping=True, random_state=42, max_iter=10000),\n",
        "            'BayesianRidge': BayesianRidge(),\n",
        "            'RandomForestRegressor': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "            'SVR': SVR(kernel='rbf')\n",
        "        }\n",
        "\n",
        "        param_grids = {\n",
        "            'Lasso': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
        "            'ElasticNet': {'alpha': [0.001, 0.01, 0.1, 1], 'l1_ratio': [0.1, 0.3, 0.5]},\n",
        "            'KernelRidge': {'alpha': [0.001, 0.01, 0.1], 'gamma': [0.001, 0.01]},\n",
        "            'SGDRegressor': {'alpha': [0.0001, 0.001]},\n",
        "            'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [None, 10], 'min_samples_split': [2, 5]},\n",
        "            'SVR': {'C': [1, 10, 100], 'epsilon': [0.01, 0.1, 0.5], 'gamma': ['scale', 'auto', 0.001]}\n",
        "        }\n",
        "\n",
        "        param_dists = {\n",
        "            'Lasso': {'alpha': loguniform(0.001, 10)},\n",
        "            'ElasticNet': {'alpha': loguniform(0.001, 1), 'l1_ratio': uniform(0, 1)},\n",
        "            'KernelRidge': {'alpha': loguniform(0.001, 1), 'gamma': loguniform(0.001, 1)},\n",
        "            'SGDRegressor': {'alpha': loguniform(0.0001, 0.01)},\n",
        "            'RandomForestRegressor': {'n_estimators': randint(50, 150), 'max_depth': [None] + list(range(5, 15)), 'min_samples_split': randint(2, 10)},\n",
        "            'SVR': {'C': loguniform(0.1, 1000), 'epsilon': uniform(0.001, 1), 'gamma': loguniform(0.0001, 1)}\n",
        "        }\n",
        "\n",
        "        param_spaces = {\n",
        "            'Lasso': {'alpha': Real(0.001, 10, prior='log-uniform')},\n",
        "            'ElasticNet': {'alpha': Real(0.001, 1, prior='log-uniform'), 'l1_ratio': Real(0, 1, prior='uniform')},\n",
        "            'KernelRidge': {'alpha': Real(0.001, 1, prior='log-uniform'), 'gamma': Real(0.001, 1, prior='log-uniform')},\n",
        "            'SGDRegressor': {'alpha': Real(0.0001, 0.01, prior='log-uniform')},\n",
        "            'RandomForestRegressor': {'n_estimators': Integer(50, 150), 'max_depth': Integer(5, 15), 'min_samples_split': Integer(2, 10)},\n",
        "            'SVR': {'C': Real(0.1, 1000, prior='log-uniform'), 'epsilon': Real(0.001, 1, prior='uniform'), 'gamma': Real(0.0001, 1, prior='log-uniform')}\n",
        "        }\n",
        "\n",
        "        # Entrenar y evaluar modelos\n",
        "        st.write(\"Iniciando entrenamiento de modelos...\")\n",
        "        model_results = {}\n",
        "        for name, model in models.items():\n",
        "            st.write(f\"Entrenando modelo: {name}\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            # GridSearchCV\n",
        "            if name not in ['LinearRegression', 'BayesianRidge']:\n",
        "                st.write(f\"Optimizando {name} con GridSearchCV...\")\n",
        "                grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], scoring=scoring_optimizer, refit='mae', cv=kf, verbose=1, n_jobs=-1)\n",
        "                grid_search.fit(X_train, y_train)\n",
        "                grid_results = cross_validate(grid_search.best_estimator_, X_train, y_train, cv=kf, scoring=scoring)\n",
        "                model_results[f\"{name}_Grid\"] = {\n",
        "                    'MAE': -grid_results['test_mae'].mean(),\n",
        "                    'MSE': -grid_results['test_mse'].mean(),\n",
        "                    'R2': grid_results['test_r2'].mean(),\n",
        "                    'MAPE': -grid_results['test_mape'].mean(),\n",
        "                    'Time (s)': time.time() - start_time,\n",
        "                    'Best Estimator': grid_search.best_estimator_,\n",
        "                    'Best Params': grid_search.best_params_\n",
        "                }\n",
        "\n",
        "            # RandomizedSearchCV\n",
        "            if name not in ['LinearRegression', 'BayesianRidge']:\n",
        "                st.write(f\"Optimizando {name} con RandomizedSearchCV...\")\n",
        "                random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dists[name], n_iter=50 if name != 'RandomForestRegressor' else 10, scoring=scoring_optimizer, refit='mae', cv=kf, verbose=1, random_state=42, n_jobs=-1)\n",
        "                random_search.fit(X_train, y_train)\n",
        "                random_results = cross_validate(random_search.best_estimator_, X_train, y_train, cv=kf, scoring=scoring)\n",
        "                model_results[f\"{name}_Random\"] = {\n",
        "                    'MAE': -random_results['test_mae'].mean(),\n",
        "                    'MSE': -random_results['test_mse'].mean(),\n",
        "                    'R2': random_results['test_r2'].mean(),\n",
        "                    'MAPE': -random_results['test_mape'].mean(),\n",
        "                    'Time (s)': time.time() - start_time,\n",
        "                    'Best Estimator': random_search.best_estimator_,\n",
        "                    'Best Params': random_search.best_params_\n",
        "                }\n",
        "\n",
        "            # BayesSearchCV\n",
        "            if name not in ['LinearRegression', 'BayesianRidge']:\n",
        "                st.write(f\"Optimizando {name} con BayesSearchCV...\")\n",
        "                bayes_search = BayesSearchCV(estimator=model, search_spaces=param_spaces[name], n_iter=50 if name != 'RandomForestRegressor' else 10, scoring=scoring_optimizer, refit='mae', cv=kf, verbose=1, random_state=42, n_jobs=-1)\n",
        "                bayes_search.fit(X_train, y_train)\n",
        "                bayes_results = cross_validate(bayes_search.best_estimator_, X_train, y_train, cv=kf, scoring=scoring)\n",
        "                model_results[f\"{name}_Bayes\"] = {\n",
        "                    'MAE': -bayes_results['test_mae'].mean(),\n",
        "                    'MSE': -bayes_results['test_mse'].mean(),\n",
        "                    'R2': bayes_results['test_r2'].mean(),\n",
        "                    'MAPE': -bayes_results['test_mape'].mean(),\n",
        "                    'Time (s)': time.time() - start_time,\n",
        "                    'Best Estimator': bayes_search.best_estimator_,\n",
        "                    'Best Params': bayes_search.best_params_\n",
        "                }\n",
        "\n",
        "            # Si no requiere optimización, evaluar directamente\n",
        "            if name in ['LinearRegression', 'BayesianRidge']:\n",
        "                st.write(f\"Evaluando {name} sin optimización...\")\n",
        "                model.fit(X_train, y_train)\n",
        "                results = cross_validate(model, X_train, y_train, cv=kf, scoring=scoring)\n",
        "                model_results[name] = {\n",
        "                    'MAE': -results['test_mae'].mean(),\n",
        "                    'MSE': -results['test_mse'].mean(),\n",
        "                    'R2': results['test_r2'].mean(),\n",
        "                    'MAPE': -results['test_mape'].mean(),\n",
        "                    'Time (s)': time.time() - start_time,\n",
        "                    'Best Estimator': model,\n",
        "                    'Best Params': 'Default'\n",
        "                }\n",
        "\n",
        "        # Guardar resultados en archivo pickle\n",
        "        st.write(\"Guardando resultados en /content/model_results.pkl...\")\n",
        "        with open('/content/model_results.pkl', 'wb') as f:\n",
        "            pickle.dump(model_results, f)\n",
        "\n",
        "        # Guardar los mejores estimadores con joblib\n",
        "        st.write(\"Guardando los mejores estimadores con joblib...\")\n",
        "        for key, result in model_results.items():\n",
        "            if '_Grid' in key or '_Random' in key or '_Bayes' in key:\n",
        "                model_name = key.split('_')[0]\n",
        "                dump(result['Best Estimator'], f\"{model_name}_best_model.joblib\")\n",
        "            elif key in ['LinearRegression', 'BayesianRidge']:\n",
        "                dump(result['Best Estimator'], f\"{key}_model.joblib\")\n",
        "\n",
        "        st.write(\"Entrenamiento y evaluación completados con éxito.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error durante la ejecución: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Visualización de Resultados del Modelado\n",
        "st.header(\"Resultados del Entrenamiento de Modelos\")\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "if os.path.exists(\"/content/model_results.pkl\"):\n",
        "    with open(\"/content/model_results.pkl\", \"rb\") as f:\n",
        "        model_results = pickle.load(f)\n",
        "\n",
        "    # Convertir resultados en DataFrame para visualización\n",
        "    results_summary = []\n",
        "    for model_name, metrics in model_results.items():\n",
        "        results_summary.append({\n",
        "            \"Modelo\": model_name,\n",
        "            \"MAE\": round(metrics[\"MAE\"], 2),\n",
        "            \"MSE\": round(metrics[\"MSE\"], 2),\n",
        "            \"R2\": round(metrics[\"R2\"], 3),\n",
        "            \"MAPE (%)\": round(metrics[\"MAPE\"], 2),\n",
        "            \"Tiempo (s)\": round(metrics[\"Time (s)\"], 2)\n",
        "        })\n",
        "    results_df = pd.DataFrame(results_summary)\n",
        "    st.subheader(\"Resumen de Métricas por Modelo\")\n",
        "    st.dataframe(results_df.sort_values(by=\"MAE\"))\n",
        "\n",
        "    # Visualización de Métricas\n",
        "    metric_to_plot = st.selectbox(\"Selecciona una métrica para comparar modelos:\", [\"MAE\", \"MSE\", \"R2\", \"MAPE (%)\", \"Tiempo (s)\"])\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    sns.barplot(data=results_df.sort_values(by=metric_to_plot, ascending=(metric_to_plot != \"R2\")), x=\"Modelo\", y=metric_to_plot, ax=ax)\n",
        "    ax.set_title(f\"Comparación de Modelos según {metric_to_plot}\")\n",
        "    ax.set_ylabel(metric_to_plot)\n",
        "    ax.set_xlabel(\"Modelo\")\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Mostrar los 3 mejores modelos según MAE\n",
        "    st.subheader(\"Top 3 Modelos según MAE\")\n",
        "    top_3_models = results_df.sort_values(by=\"MAE\").head(3)\n",
        "    st.dataframe(top_3_models)\n",
        "\n",
        "    # Comparación gráfica de los 3 mejores modelos\n",
        "    st.subheader(\"Comparación Gráfica de los 3 Mejores Modelos según MAE\")\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.barplot(data=top_3_models, x=\"Modelo\", y=\"MAE\", ax=ax)\n",
        "    ax.set_title(\"Top 3 Modelos según MAE\")\n",
        "    ax.set_ylabel(\"MAE\")\n",
        "    ax.set_xlabel(\"Modelo\")\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "else:\n",
        "    st.warning(\"El archivo '/content/model_results.pkl' no se encuentra. Por favor, ejecuta el entrenamiento de modelos primero.\")\n",
        "\n",
        "# Documentación Formal: Conclusión\n",
        "st.header('Conclusión')\n",
        "st.markdown(\"\"\"\n",
        "El análisis exploratorio, preprocesamiento y modelización del dataset Ames Housing han permitido preparar los datos y entrenar modelos predictivos para 'SalePrice'. El preprocesamiento abordó valores faltantes, codificación de variables categóricas, ingeniería de características y escalado. Las visualizaciones del EDA identificaron patrones clave, como el sesgo en 'SalePrice' y la importancia de variables como 'OverallQual'. Los modelos fueron optimizados y evaluados, con los mejores resultados guardados para análisis futuros. Este dashboard permite explorar los datos y comparar modelos de manera interactiva.\n",
        "\"\"\")\n",
        "\n",
        "# ... (código previo de TAM.py hasta la sección de \"Resultados del Entrenamiento de Modelos\")\n",
        "\n",
        "# Visualización de Resultados del Modelado\n",
        "st.header(\"Resultados del Entrenamiento de Modelos\")\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "if os.path.exists(\"/content/model_results.pkl\"):\n",
        "    with open(\"/content/model_results.pkl\", \"rb\") as f:\n",
        "        model_results = pickle.load(f)\n",
        "\n",
        "    # Convertir resultados en DataFrame para visualización\n",
        "    results_summary = []\n",
        "\n",
        "    # Ensure X_test and y_test are available when running the prediction visualization\n",
        "if 'X_test' not in locals():\n",
        "    st.warning(\"Variables de prueba (X_test, y_test) no encontradas. Volviendo a cargar y dividir datos...\")\n",
        "    try:\n",
        "        df = pd.read_csv('preprocessed_data.csv')\n",
        "        if 'SalePrice' in df.columns:\n",
        "            y = df['SalePrice']\n",
        "            X = df.drop('SalePrice', axis=1)\n",
        "        else:\n",
        "\n",
        "            st.stop()\n",
        "        X = X.select_dtypes(include=np.number)\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"Error: Asegúrese de que el archivo 'preprocessed_data.csv' esté disponible.\")\n",
        "        st.stop()\n",
        "    for model_name, metrics in model_results.items():\n",
        "        results_summary.append({\n",
        "            \"Modelo\": model_name,\n",
        "            \"MAE\": round(metrics[\"MAE\"], 2),\n",
        "            \"MSE\": round(metrics[\"MSE\"], 2),\n",
        "            \"R2\": round(metrics[\"R2\"], 3),\n",
        "            \"MAPE (%)\": round(metrics[\"MAPE\"], 2),\n",
        "            \"Tiempo (s)\": round(metrics[\"Time (s)\"], 2)\n",
        "        })\n",
        "    results_df = pd.DataFrame(results_summary)\n",
        "    st.subheader(\"Resumen de Métricas por Modelo\")\n",
        "    st.dataframe(results_df.sort_values(by=\"MAE\"))\n",
        "\n",
        "    # Visualización de Métricas\n",
        "    metric_to_plot = st.selectbox(\"Selecciona una métrica para comparar modelos:\", [\"MAE\", \"MSE\", \"R2\", \"MAPE (%)\", \"Tiempo (s)\"], key=\"metric_selector_1\")\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    sns.barplot(data=results_df.sort_values(by=metric_to_plot, ascending=(metric_to_plot != \"R2\")), x=\"Modelo\", y=metric_to_plot, ax=ax)\n",
        "    ax.set_title(f\"Comparación de Modelos según {metric_to_plot}\")\n",
        "    ax.set_ylabel(metric_to_plot)\n",
        "    ax.set_xlabel(\"Modelo\")\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Scatter Plot de Valores Predichos vs Reales para Todos los Modelos\n",
        "    st.subheader(\"Scatter Plot de Valores Predichos vs Reales para Todos los Modelos\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Este gráfico muestra los valores predichos frente a los valores reales de 'SalePrice'. Los puntos cercanos a la línea diagonal (y=x) indican predicciones precisas.\n",
        "    \"\"\")\n",
        "    selected_model = st.selectbox(\"Selecciona un modelo:\", list(model_results.keys()))\n",
        "    best_estimator = model_results[selected_model]['Best Estimator']\n",
        "    y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.scatter(y_test, y_pred, alpha=0.5, color='blue')\n",
        "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    ax.set_xlabel('Valores Reales')\n",
        "    ax.set_ylabel('Valores Predichos')\n",
        "    ax.set_title(f'Scatter Plot para {selected_model}')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Gráfica de Residuos para Todos los Modelos\n",
        "    st.subheader(\"Gráfica de Residuos para Todos los Modelos\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Este gráfico muestra los residuos (valor real - predicho) frente a los valores predichos. Un patrón aleatorio alrededor de cero indica un modelo robusto.\n",
        "    \"\"\")\n",
        "    selected_model = st.selectbox(\"Selecciona un modelo para residuos:\", list(model_results.keys()))\n",
        "    best_estimator = model_results[selected_model]['Best Estimator']\n",
        "    y_pred = best_estimator.predict(X_test)\n",
        "    residuals = y_test - y_pred\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.scatter(y_pred, residuals, alpha=0.5, color='green')\n",
        "    ax.axhline(y=0, color='r', linestyle='--')\n",
        "    ax.set_xlabel('Valores Predichos')\n",
        "    ax.set_ylabel('Residuos')\n",
        "    ax.set_title(f'Residuos para {selected_model}')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Gráfica de Importancia de Características para Modelos Aplicables\n",
        "    st.subheader(\"Importancia de Características para Modelos Aplicables\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Este gráfico muestra la importancia de las características para modelos como RandomForestRegressor. Para otros modelos, se indica si no es aplicable.\n",
        "    \"\"\")\n",
        "    rf_models = [key for key in model_results.keys() if '_RandomForest' in key]\n",
        "    if rf_models:\n",
        "        selected_rf_model = st.selectbox(\"Selecciona un modelo RandomForest:\", rf_models)\n",
        "        best_estimator = model_results[selected_rf_model]['Best Estimator']\n",
        "        if hasattr(best_estimator, 'feature_importances_'):\n",
        "            importances = best_estimator.feature_importances_\n",
        "            feature_names = X.columns\n",
        "            importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(10)\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            sns.barplot(x='importance', y='feature', data=importance_df, ax=ax)\n",
        "            ax.set_title(f'Importancia de Características para {selected_rf_model}')\n",
        "            ax.set_xlabel('Importancia')\n",
        "            ax.set_ylabel('Características')\n",
        "            st.pyplot(fig)\n",
        "        else:\n",
        "            st.write(f\"{selected_rf_model} no proporciona importancia de características.\")\n",
        "    else:\n",
        "        st.write(\"No hay modelos RandomForest disponibles.\")\n",
        "\n",
        "    # Mostrar los 3 mejores modelos según MAE\n",
        "    st.subheader(\"Top 3 Modelos según MAE\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Esta tabla muestra los tres modelos con el menor MAE, junto con sus métricas de rendimiento.\n",
        "    \"\"\")\n",
        "    top_3_models = results_df.sort_values(by=\"MAE\").head(3)\n",
        "    st.dataframe(top_3_models)\n",
        "\n",
        "    # Comparación Gráfica de los 3 Mejores Modelos\n",
        "    st.subheader(\"Comparación Gráfica de los 3 Mejores Modelos según MAE\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Este gráfico de barras compara el MAE de los tres mejores modelos, destacando su rendimiento relativo.\n",
        "    \"\"\")\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.barplot(data=top_3_models, x=\"Modelo\", y=\"MAE\", ax=ax)\n",
        "    ax.set_title(\"Top 3 Modelos según MAE\")\n",
        "    ax.set_ylabel(\"MAE\")\n",
        "    ax.set_xlabel(\"Modelo\")\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Scatter Plot de los 3 Mejores Modelos\n",
        "    st.subheader(\"Scatter Plot de los 3 Mejores Modelos según MAE\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Estos gráficos muestran los valores predichos frente a los reales para los tres mejores modelos, permitiendo una comparación visual de su precisión.\n",
        "    \"\"\")\n",
        "    top_3 = sorted(model_results.items(), key=lambda x: x[1]['MAE'])[:3]\n",
        "    top_3_keys = [key for key, _ in top_3]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    for i, key in enumerate(top_3_keys):\n",
        "        best_estimator = model_results[key]['Best Estimator']\n",
        "        y_pred = best_estimator.predict(X_test)\n",
        "        axes[i].scatter(y_test, y_pred, alpha=0.5, color='blue')\n",
        "        axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "        axes[i].set_xlabel('Valores Reales')\n",
        "        axes[i].set_ylabel('Valores Predichos')\n",
        "        axes[i].set_title(f'{key}')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Gráfica de Residuos para los 3 Mejores Modelos\n",
        "    st.subheader(\"Gráfica de Residuos para los 3 Mejores Modelos según MAE\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Estos gráficos muestran los residuos frente a los valores predichos para los tres mejores modelos, ayudando a evaluar la consistencia de los errores.\n",
        "    \"\"\")\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    for i, key in enumerate(top_3_keys):\n",
        "        best_estimator = model_results[key]['Best Estimator']\n",
        "        y_pred = best_estimator.predict(X_test)\n",
        "        residuals = y_test - y_pred\n",
        "        axes[i].scatter(y_pred, residuals, alpha=0.5, color='green')\n",
        "        axes[i].axhline(y=0, color='r', linestyle='--')\n",
        "        axes[i].set_xlabel('Valores Predichos')\n",
        "        axes[i].set_ylabel('Residuos')\n",
        "        axes[i].set_title(f'{key}')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Distribución de Errores para los 3 Mejores Modelos\n",
        "    st.subheader(\"Distribución de Errores para los 3 Mejores Modelos según MAE\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Descripción:** Estos histogramas muestran la distribución de los residuos para los tres mejores modelos, permitiendo comparar la estabilidad de sus errores.\n",
        "    \"\"\")\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    for i, key in enumerate(top_3_keys):\n",
        "        best_estimator = model_results[key]['Best Estimator']\n",
        "        y_pred = best_estimator.predict(X_test)\n",
        "        residuals = y_test - y_pred\n",
        "        sns.histplot(residuals, kde=True, ax=axes[i], color='purple')\n",
        "        axes[i].set_title(f'Distribución de Residuos para {key}')\n",
        "        axes[i].set_xlabel('Residuos')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "else:\n",
        "    st.warning(\"El archivo '/content/model_results.pkl' no se encuentra. Por favor, ejecuta el entrenamiento de modelos primero.\")\n",
        "\n",
        "# Documentación Formal: Conclusión\n",
        "st.header('Conclusión')\n",
        "st.markdown(\"\"\"\n",
        "El análisis exploratorio, preprocesamiento y modelización del dataset Ames Housing han permitido preparar los datos y entrenar modelos predictivos para 'SalePrice'. El preprocesamiento abordó valores faltantes, codificación de variables categóricas, ingeniería de características y escalado. Las visualizaciones del EDA identificaron patrones clave, como el sesgo en 'SalePrice' y la importancia de variables como 'OverallQual'. Los modelos fueron optimizados y evaluados, con los mejores resultados guardados para análisis futuros. Este dashboard permite explorar los datos y comparar modelos de manera interactiva, con gráficos que destacan la precisión, los errores y la importancia de las características.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "DrW3pCPNNpco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "metadata": {
        "id": "672FiOG6bSOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dashboard"
      ],
      "metadata": {
        "id": "rzUBB4QLHas_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "#Ejecutar Streamlit\n",
        "!streamlit run TAMExam1.py &>/content/logs.txt & #Cambiar TAMExam1.py por el nombre de tu archivo principal\n",
        "\n",
        "#Exponer el puerto 8501 con Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "#Leer la URL pública generada por Cloudflare\n",
        "import time\n",
        "time.sleep(5)  # Esperar que se genere la URL\n",
        "\n",
        "import re\n",
        "found_context = False  # Indicador para saber si estamos en la sección correcta\n",
        "\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        #Detecta el inicio del contexto que nos interesa\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        #Busca una URL si ya se encontró el contexto relevante\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)\n",
        "            if match:\n",
        "                url = match.group(0)  #Extrae la URL encontrada\n",
        "                print(f'Tu aplicación está disponible en: {url}')\n",
        "                break  #Termina el bucle después de encontrar la URL"
      ],
      "metadata": {
        "id": "XyzQ_zdcINWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "res = input(\"Digite (1) para finalizar la ejecución del Dashboard: \")\n",
        "\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Termina el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")"
      ],
      "metadata": {
        "id": "t5AIhWeyIQqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 <PID>"
      ],
      "metadata": {
        "id": "ydR1pD7BWxqM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}